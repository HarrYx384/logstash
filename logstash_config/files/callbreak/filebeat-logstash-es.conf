input {
    http {
        host => "0.0.0.0"
        port => "8080"
    }
}

filter {
    if [source] == "/var/log/mpl/service-callbreak-monitoring.log" {
        grok {
            id => "callbreak-monitoring"
            add_tag => ["elk-logs-logstash-callbreak-dcdb","grokparse-success"]
            tag_on_failure => ["elk-logs-logstash-callbreak-dcdb", "callbreak-monitoring-grokparsefailure"]
            match => { "message" => '^(?<timestamp>%{TIMESTAMP_ISO8601}) RoomCount: (%{NUMBER:roomcount:int}) UserCount: (%{NUMBER:usercount:int})'}
        }
    }
    else {
        mutate {
            id => "not-parsed"
            add_tag => ["elk-logs-logstash-callbreak-dcdb", "not-parsed"]
        }
    }

    mutate {
        remove_field => [ "host" ]
    }

    if [timestamp] {
        mutate {
            id => "save-logstash-timestamp"
            copy => { "@timestamp" => "logstash_timestamp" }
        }
        date {
            id => "match-date"
            match => ["timestamp", "dd/MMM/yyyy:HH:mm:ss Z", "dd MMM yyyy | HH:mm:ss,SSS", "yyyy-MM-dd HH:mm:ss,SSS", "MMM dd HH:mm:ss", "ISO8601"]
            remove_field => ["timestamp"]
        }
        if "_dateparsefailure" not in [tags] {
            ruby {
                id => "calulate-processing-time"
                init => "require 'time'"
                code => "
                diff = event.get('logstash_timestamp') - event.get('@timestamp');
                event.set('processing_time', diff.to_f);
                "
            add_tag => [ "processing_time_calculated" ]
            }
        }
    }
    if [source] {
        ruby {
            code => "
                filename = event.get('[source]').split('/').last
                event.set('service',(filename.split('.').first).split('service-').last)
                "
        }
    }
}

output {
    elasticsearch {
        hosts => ["https://elk-logs-elasticsearch-data-node-01.mpl.live:9200","https://elk-logs-elasticsearch-data-node-02.mpl.live:9200","https://elk-logs-elasticsearch-data-node-03.mpl.live:9200","https://elk-logs-elasticsearch-data-node-04.mpl.live:9200","https://elk-logs-elasticsearch-data-node-05.mpl.live:9200","https://elk-logs-elasticsearch-data-node-06.mpl.live:9200","https://elk-logs-elasticsearch-data-node-07.mpl.live:9200","https://elk-logs-elasticsearch-data-node-08.mpl.live:9200","https://elk-logs-elasticsearch-data-node-09.mpl.live:9200","https://elk-logs-elasticsearch-data-node-10.mpl.live:9200","https://elk-logs-elasticsearch-data-node-11.mpl.live:9200","https://elk-logs-elasticsearch-data-node-12.mpl.live:9200","https://elk-logs-elasticsearch-data-node-13.mpl.live:9200","https://elk-logs-elasticsearch-data-node-14.mpl.live:9200","https://elk-logs-elasticsearch-data-node-15.mpl.live:9200","https://elk-logs-elasticsearch-data-node-16.mpl.live:9200","https://elk-logs-elasticsearch-data-node-17.mpl.live:9200","https://elk-logs-elasticsearch-data-node-18.mpl.live:9200","https://elk-logs-elasticsearch-data-node-19.mpl.live:9200","https://elk-logs-elasticsearch-data-node-20.mpl.live:9200"]
        ilm_enabled => true
        cacert => '/etc/logstash/certs/DigiCertCA.crt'
        ssl_certificate_verification => true
        ssl => true
        user => "logstash_writer"
        password => "M4HCf7x2Xqu0Tmqz"
        manage_template => false
        index => "logstash-callbreak-%{+yyyy.MM.dd}"
    }
}
